import os
import requests
import xml.etree.ElementTree as ET
from datetime import datetime

# ì„¤ì •
SAVE_PDF_DIR = "/Users/jeong/AI/learnmate/data/papers"
SAVE_MD_DIR = "/Users/jeong/AI/learnmate/data/abstracts"
MAX_RESULTS = 10
TITLE_SLICE = 60

# ê²€ìƒ‰ì–´ (ì œëª©/ì´ˆë¡ì— ì œí•œ, ëª…í™•í•œ AND ì¡°ê±´)
SEARCH_QUERY = '(ti:"learning" OR abs:"learning") AND (ti:"students" OR abs:"students")'


# íŒŒì¼ëª… ì •ë¦¬
def sanitize_filename(text):
    return "".join(c for c in text if c.isalnum() or c in " ._-").rstrip()

# ë…¼ë¬¸ ê°€ì ¸ì˜¤ê¸°
def fetch_arxiv():
    os.makedirs(SAVE_PDF_DIR, exist_ok=True)
    os.makedirs(SAVE_MD_DIR, exist_ok=True)

    print(f"ğŸ“¡ arXivì—ì„œ ê²€ìƒ‰ ì¤‘...")

    base_url = "http://export.arxiv.org/api/query"
    params = {
        "search_query": SEARCH_QUERY,
        "start": 0,
        "max_results": MAX_RESULTS,
        "sortBy": "submittedDate",
        "sortOrder": "descending"
    }

    try:
        res = requests.get(base_url, params=params)
        res.raise_for_status()
    except Exception as e:
        print(f"âŒ arXiv ìš”ì²­ ì‹¤íŒ¨: {e}")
        return

    root = ET.fromstring(res.text)
    ns = {"atom": "http://www.w3.org/2005/Atom"}

    entries = root.findall("atom:entry", ns)
    print(f"ğŸ” ì´ {len(entries)}í¸ ë…¼ë¬¸ ë°œê²¬\n")

    for entry in entries:
        try:
            title = entry.find("atom:title", ns).text.strip()
            summary = entry.find("atom:summary", ns).text.strip()
            pdf_url = entry.find("atom:id", ns).text.strip().replace("abs", "pdf")

            filename_base = sanitize_filename(title[:TITLE_SLICE])
            md_path = os.path.join(SAVE_MD_DIR, f"{filename_base}.md")
            pdf_path = os.path.join(SAVE_PDF_DIR, f"{filename_base}.pdf")

            # Markdown ì €ì¥
            with open(md_path, "w", encoding="utf-8") as f:
                f.write(f"# {title}\n\n")
                f.write(f"**Abstract:**\n{summary}\n\n")
                f.write(f"[arXiv ì›ë¬¸ ë§í¬]({pdf_url})\n")
            print(f"ğŸ“ ìš”ì•½ ì €ì¥ ì™„ë£Œ: {md_path}")

            # PDF ë‹¤ìš´ë¡œë“œ ë° ì‚­ì œ
            pdf_res = requests.get(pdf_url + ".pdf")
            pdf_res.raise_for_status()

            with open(pdf_path, "wb") as f:
                f.write(pdf_res.content)
            print(f"âœ… PDF ì €ì¥ ì™„ë£Œ: {pdf_path}")

            os.remove(pdf_path)
            print(f"ğŸ—‘ PDF ì‚­ì œ ì™„ë£Œ: {pdf_path}\n")

        except Exception as e:
            print(f"âš ï¸ ë…¼ë¬¸ '{title}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}\n")

if __name__ == "__main__":
    print(f"â± ì‹¤í–‰ ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    fetch_arxiv()