import os
import pdfplumber
from openai import OpenAI
from textwrap import wrap
from dotenv import load_dotenv
from datetime import datetime

# ê²½ë¡œ ì„¤ì •
PDF_DIR = "/Users/jeong/AI/learnmate/data/papers"
SUMMARY_DIR = "/Users/jeong/AI/learnmate/data/abstracts"

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# í…ìŠ¤íŠ¸ ì¶”ì¶œ
def extract_text_from_pdf(pdf_path):
    try:
        text = ""
        with pdfplumber.open(pdf_path) as pdf:
            for i, page in enumerate(pdf.pages):
                text += page.extract_text() or ""
        return text.strip()
    except Exception as e:
        print(f"âŒ PDF ë¡œë”© ì˜¤ë¥˜ ({pdf_path}): {e}")
        return ""

# í…ìŠ¤íŠ¸ë¥¼ ë¬¸ììˆ˜ ê¸°ì¤€ìœ¼ë¡œ ìª¼ê°œê¸°
def chunk_text(text, max_chars=4000):
    return wrap(text, width=max_chars)

# ë‹¨ì¼ chunk ìš”ì•½
def summarize_single_chunk(chunk):
    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” êµìœ¡ ê´€ë ¨ ë…¼ë¬¸ì„ ìš”ì•½í•˜ëŠ” í•œêµ­ì–´ ì „ë¬¸ê°€ì•¼. í•µì‹¬ì„ ì¡°ë¦¬ ìˆê²Œ ìš”ì•½í•´ì¤˜."},
                {"role": "user", "content": f"ë‹¤ìŒ ë‚´ìš©ì„ ìš”ì•½í•´ì¤˜:\n{chunk}"}
            ],
            max_tokens=800,
            temperature=0.3
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"âŒ ìš”ì•½ ì‹¤íŒ¨: {e}")
        return ""

# ì „ì²´ ë¬¸ì„œ ìš”ì•½
def summarize_text(text):
    chunks = chunk_text(text)
    partial_summaries = []

    # 1ì°¨ chunk ìš”ì•½
    for idx, chunk in enumerate(chunks):
        print(f"âœ‚ï¸ Chunk {idx+1}/{len(chunks)} ìš”ì•½ ì¤‘...")
        partial_summary = summarize_single_chunk(chunk)
        if partial_summary:
            partial_summaries.append(partial_summary)

    combined_summary = "\n".join(partial_summaries)

    # 2ì°¨ ìµœì¢… ìš”ì•½
    print("\nğŸŒ€ 2ì°¨ ìµœì¢… ìš”ì•½ ì¤‘...")
    final_summary = summarize_single_chunk(combined_summary)
    return final_summary

# ìš”ì•½ ì €ì¥
def save_summary_to_md(title, summary):
    filename = "".join(c for c in title[:60] if c.isalnum() or c in " ._-").rstrip().replace(" ", "_") + ".md"
    path = os.path.join(SUMMARY_DIR, filename)
    with open(path, "w", encoding="utf-8") as f:
        f.write(f"# {title}\n\n{summary}\n")
    print(f"âœ… ìš”ì•½ ì €ì¥ ì™„ë£Œ: {path}")

# ì „ì²´ íŒŒì´í”„ë¼ì¸
def run_pipeline():
    os.makedirs(SUMMARY_DIR, exist_ok=True)

    for filename in os.listdir(PDF_DIR):
        if not filename.endswith(".pdf"):
            continue

        pdf_path = os.path.join(PDF_DIR, filename)
        print(f"\nğŸ“„ ë…¼ë¬¸ ì²˜ë¦¬ ì‹œì‘: {filename} ({datetime.now().strftime('%H:%M:%S')})")

        text = extract_text_from_pdf(pdf_path)
        if not text:
            continue

        summary = summarize_text(text)
        if not summary:
            continue

        save_summary_to_md(filename.replace(".pdf", ""), summary)

        os.remove(pdf_path)
        print(f"ğŸ—‘ PDF ì‚­ì œ ì™„ë£Œ: {pdf_path}")

# ì‹¤í–‰
if __name__ == "__main__":
    print(f"â± ì‹¤í–‰ ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    run_pipeline()
